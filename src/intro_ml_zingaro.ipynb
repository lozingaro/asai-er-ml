{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio di Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avremo bisogno di alcune librerie esterne a Python:\n",
    "\n",
    "- [Random](https://docs.python.org/3/library/random.html): libreria per la generazione di numeri pseudo-casuali\n",
    "- [Matplotlib](https://matplotlib.org/): libreria per la visualizzazione dei dati\n",
    "- [Math](https://docs.python.org/3/library/math.html): libreria per le funzioni matematiche\n",
    "\n",
    "Per installare le librerie esterne a Python, se non le avete già, potete usare il comando `pip` da terminale:\n",
    "\n",
    "```bash\n",
    "pip install matplotlib\n",
    "```\n",
    "\n",
    "Per verificare che le librerie siano state installate correttamente, potete eseguire il seguente codice:\n",
    "\n",
    "```python\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "Se non ci sono errori, allora le librerie sono state installate correttamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline della lezione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa lezione di laboratorio, andremo a completare il seguente codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punto 2: Algoritmi di apprendimento supervisionato\n",
    "\n",
    "# Modello lineare per la regressione\n",
    "def linear_regression(X, y):\n",
    "    # Implementazione dell'algoritmo di regressione lineare\n",
    "    # ...\n",
    "    return model\n",
    "\n",
    "# Modello lineare per la classificazione\n",
    "\n",
    "\n",
    "def linear_classification(X, y):\n",
    "    # Implementazione dell'algoritmo di classificazione lineare\n",
    "    # ...\n",
    "    return model\n",
    "\n",
    "# Punto 3: Tecniche di validazione dei modelli\n",
    "\n",
    "# Divisione del dataset in train set e test set\n",
    "\n",
    "\n",
    "def train_test_split(X, y, test_size):\n",
    "    # Implementazione della divisione del dataset\n",
    "    # ...\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Leave-One-Out Cross Validation\n",
    "\n",
    "\n",
    "def leave_one_out_cross_validation(X, y):\n",
    "    # Implementazione della leave-one-out cross validation\n",
    "    # ...\n",
    "    return scores\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "\n",
    "\n",
    "def k_fold_cross_validation(X, y, k):\n",
    "    # Implementazione della k-fold cross validation\n",
    "    # ...\n",
    "    return scores\n",
    "\n",
    "# Metriche di valutazione per la classificazione binaria\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # Implementazione del calcolo dell'accuratezza\n",
    "    # ...\n",
    "    return acc\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # Implementazione del calcolo della precisione\n",
    "    # ...\n",
    "    return prec\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Implementazione del calcolo della sensibilità (recall)\n",
    "    # ...\n",
    "    return rec\n",
    "\n",
    "# Punto 4: Modelli oltre quelli lineari\n",
    "\n",
    "# Modelli polinomiali con Support Vector Machine (SVM)\n",
    "\n",
    "\n",
    "def support_vector_machine(X, y):\n",
    "    # Implementazione del modello SVM polinomiale\n",
    "    # ...\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelli lineari per la regressione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'esempio sopra, vengono generati dei dati casuali X e y in cui y è ottenuto come una **linea retta con rumore**. \n",
    "\n",
    "L'algoritmo di regressione lineare viene implementato nella funzione `linear_regression` che calcola i coefficienti della retta di regressione. \n",
    "\n",
    "Successivamente, il modello viene addestrato utilizzando i dati e infine viene tracciata la retta di regressione nel plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generazione di dati casuali\n",
    "random.seed(42)\n",
    "\n",
    "num_samples = 100\n",
    "X = [random.uniform(0, 10) for _ in range(num_samples)]\n",
    "y = [2 * x + random.uniform(-1, 1) for x in X]\n",
    "\n",
    "# Implementazione della regressione lineare\n",
    "\n",
    "\n",
    "def linear_regression(X, y):\n",
    "    num_samples = len(X)\n",
    "    sum_x = sum(X)\n",
    "    sum_y = sum(y)\n",
    "    sum_xy = sum(x * y for x, y in zip(X, y))\n",
    "    sum_xx = sum(x * x for x in X)\n",
    "\n",
    "    slope = (num_samples * sum_xy - sum_x * sum_y) / \\\n",
    "        (num_samples * sum_xx - sum_x * sum_x)\n",
    "    intercept = (sum_y - slope * sum_x) / num_samples\n",
    "\n",
    "    return slope, intercept\n",
    "\n",
    "\n",
    "# Addestramento del modello di regressione lineare\n",
    "slope, intercept = linear_regression(X, y)\n",
    "\n",
    "# Plot del dataset e della regressione lineare\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X, y, c='blue')\n",
    "plt.plot([min(X), max(X)], [slope * min(X) + intercept,\n",
    "         slope * max(X) + intercept], color='red')\n",
    "plt.title('Regressione Lineare')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelli lineari per la classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'implementazione della funzione `logistic_regression`, abbiamo utilizzato la **funzione sigmoide** `sigmoid` per calcolare la trasformazione logistica dei valori `z`. \n",
    "\n",
    "Successivamente, abbiamo addestrato il modello utilizzando **il metodo del gradiente discendente** per ottimizzare i pesi e il bias. \n",
    "\n",
    "Infine, abbiamo utilizzato i pesi ottimizzati per prevedere le etichette per il set di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generazione di dati casuali\n",
    "random.seed(42)\n",
    "\n",
    "num_samples = 100\n",
    "X1 = [[random.gauss(2, 1), random.gauss(2, 1)] for _ in range(num_samples)]\n",
    "X2 = [[random.gauss(-2, 1), random.gauss(-2, 1)] for _ in range(num_samples)]\n",
    "X = X1 + X2\n",
    "y = [1] * num_samples + [-1] * num_samples\n",
    "\n",
    "# Implementazione della funzione di regressione logistica\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + math.exp(-z))\n",
    "\n",
    "\n",
    "def logistic_regression(X, y, learning_rate=0.01, num_iterations=1000):\n",
    "    num_samples = len(X)\n",
    "    num_features = len(X[0])\n",
    "    w = [0] * num_features\n",
    "    b = 0\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        dw = [0] * num_features\n",
    "        db = 0\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            # Calcolo del valore predetto\n",
    "            z = b\n",
    "            for j in range(num_features):\n",
    "                z += w[j] * X[i][j]\n",
    "            y_pred = sigmoid(z)\n",
    "\n",
    "            # Aggiornamento dei pesi e del bias\n",
    "            for j in range(num_features):\n",
    "                dw[j] += (y_pred - y[i]) * X[i][j]\n",
    "            db += y_pred - y[i]\n",
    "\n",
    "        # Aggiornamento dei pesi e del bias\n",
    "        for j in range(num_features):\n",
    "            w[j] -= learning_rate * dw[j] / num_samples\n",
    "        b -= learning_rate * db / num_samples\n",
    "\n",
    "    # Previsione delle etichette\n",
    "    y_pred = []\n",
    "    for i in range(num_samples):\n",
    "        z = b\n",
    "        for j in range(num_features):\n",
    "            z += w[j] * X[i][j]\n",
    "        y_pred.append(1 if sigmoid(z) >= 0.5 else -1)\n",
    "\n",
    "    return y_pred, w, b\n",
    "\n",
    "# Addestramento e valutazione del modello di regressione logistica\n",
    "\n",
    "\n",
    "# Addestramento del modello di regressione logistica\n",
    "y_pred_logistic, weights, bias = logistic_regression(X, y)\n",
    "\n",
    "# Plot del dataset e della regressione logistica\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter([x[0] for i, x in enumerate(X) if y[i] == 1], [x[1]\n",
    "            for i, x in enumerate(X) if y[i] == 1], c='blue', label='Classe 1')\n",
    "plt.scatter([x[0] for i, x in enumerate(X) if y[i] == -1], [x[1]\n",
    "            for i, x in enumerate(X) if y[i] == -1], c='orange', label='Classe -1')\n",
    "plt.plot([-4, 4], [(-bias - weights[0] * (-4)) / weights[1],\n",
    "         (-bias - weights[0] * 4) / weights[1]], color='red')\n",
    "plt.title('Regressione Logistica')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tecniche di validazione dei modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supponiamo di avere un dataset fittizio composto da 100 campioni, in cui ogni campione è rappresentato da due feature (variabili) e ha un'etichetta di classe binaria (0 o 1). Vogliamo valutare le prestazioni di un modello di classificazione su questo dataset utilizzando le tecniche di validazione dei modelli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generazione di un dataset fittizio\n",
    "random.seed(42)\n",
    "\n",
    "num_samples = 100\n",
    "X = [[random.uniform(-2, 2), random.uniform(-2, 2)]\n",
    "     for _ in range(num_samples)]\n",
    "y = [random.choice([0, 1]) for _ in range(num_samples)]\n",
    "\n",
    "# Plot del dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['blue' if label == 0 else 'red' for label in y]\n",
    "plt.scatter([x[0] for x in X], [x[1] for x in X], c=colors)\n",
    "plt.title('Dataset')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "# set legend according to color, shape is circular\n",
    "plt.legend(handles=[plt.Line2D([], [], color='blue', marker='o', linestyle='None'),\n",
    "                    plt.Line2D([], [], color='red', marker='o', linestyle='None')],\n",
    "           labels=['Classe 0', 'Classe 1'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisione del dataset in train set e test set\n",
    "\n",
    "Iniziamo dividendo il dataset in un train set e un test set. La funzione train_test_split crea una divisione casuale del dataset, assegnando una proporzione test_size di campioni al test set e il resto al train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione del dataset in train set e test set\n",
    "\n",
    "def train_test_split(X, y, test_size):\n",
    "    num_samples = len(X)\n",
    "    num_test_samples = int(num_samples * test_size)\n",
    "    shuffled_indices = list(range(num_samples))\n",
    "    random.shuffle(shuffled_indices)\n",
    "\n",
    "    X_train = [X[i] for i in shuffled_indices[num_test_samples:]]\n",
    "    y_train = [y[i] for i in shuffled_indices[num_test_samples:]]\n",
    "    X_test = [X[i] for i in shuffled_indices[:num_test_samples]]\n",
    "    y_test = [y[i] for i in shuffled_indices[:num_test_samples]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# split the dataset into train and test set\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Successivamente, eseguiamo la Leave-One-Out Cross Validation. \n",
    "Questa tecnica addestra il modello su tutti i campioni tranne uno e valuta il modello su quel campione escluso. \n",
    "Ripetiamo questa procedura per ogni campione nel dataset, calcolando la valutazione del modello. \n",
    "La funzione `leave_one_out_cross_validation` implementa questa tecnica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One-Out Cross Validation\n",
    "def leave_one_out_cross_validation(X, y):\n",
    "    num_samples = len(X)\n",
    "    scores = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        X_train = X[:i] + X[i+1:]\n",
    "        y_train = y[:i] + y[i+1:]\n",
    "        X_test = [X[i]]\n",
    "        y_test = [y[i]]\n",
    "\n",
    "        # Addestramento e valutazione del modello\n",
    "\n",
    "        # ...\n",
    "\n",
    "        # Sostituisci con la valutazione del modello corretta\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot della composizione degli split e dei fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione del dataset in train set e test set\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter([x[0] for x in X_train], [x[1]\n",
    "            for x in X_train], c=y_train, cmap=plt.cm.Paired)\n",
    "plt.scatter([x[0] for x in X_test], [x[1]\n",
    "            for x in X_test], c=y_test, cmap=plt.cm.Paired, marker='s')\n",
    "plt.title('Divisione del dataset in train set e test set')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend(['Train Set', 'Test Set'])\n",
    "\n",
    "# Leave-One-Out Cross Validation\n",
    "plt.subplot(1, 2, 2)\n",
    "colors = ['r', 'g', 'b', 'c', 'm']\n",
    "for i in range(num_samples):\n",
    "    train_indices = list(range(i)) + list(range(i+1, num_samples))\n",
    "    test_indices = [i]\n",
    "\n",
    "    X_train = [X[j] for j in train_indices]\n",
    "    y_train = [y[j] for j in train_indices]\n",
    "    X_test = [X[j] for j in test_indices]\n",
    "    y_test = [y[j] for j in test_indices]\n",
    "\n",
    "    plt.scatter([x[0] for x in X_train], [x[1]\n",
    "                for x in X_train], c=colors[i % len(colors)], marker='x')\n",
    "    plt.scatter([x[0] for x in X_test], [x[1]\n",
    "                for x in X_test], c=colors[i % len(colors)], marker='o')\n",
    "plt.title('Leave-One-Out Cross Validation')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend(['Train Set', 'Test Set'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation\n",
    "\n",
    "Infine, utilizziamo la tecnica K-Fold Cross Validation. \n",
    "\n",
    "Questa tecnica suddivide il dataset in K fold (in questo caso, impostiamo il parametro k) e addestra il modello su K-1 fold, valutandolo sul fold rimanente. \n",
    "\n",
    "Ripetiamo questa procedura K volte, ogni volta utilizzando un fold diverso come set di test. \n",
    "\n",
    "La funzione `k_fold_cross_validation` implementa questa tecnica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "\n",
    "def k_fold_cross_validation(X, y, k):\n",
    "    num_samples = len(X)\n",
    "    fold_size = num_samples // k\n",
    "    scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size\n",
    "\n",
    "        X_train = X[:start] + X[end:]\n",
    "        y_train = y[:start] + y[end:]\n",
    "        X_test = X[start:end]\n",
    "        y_test = y[start:end]\n",
    "\n",
    "        # Addestramento e valutazione del modello\n",
    "\n",
    "        # ...\n",
    "\n",
    "        # Sostituisci con la valutazione del modello corretta\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metriche per la valutazione di classificatori binari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supponiamo di avere lo stesso dataset fittizio composto da 100 campioni del precedente esempio, in cui ogni campione è rappresentato da due feature (variabili) e ha un'etichetta di classe binaria (0 o 1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generazione di un dataset fittizio\n",
    "random.seed(42)\n",
    "\n",
    "num_samples = 100\n",
    "X = [[random.uniform(-2, 2), random.uniform(-2, 2)]\n",
    "     for _ in range(num_samples)]\n",
    "y = [random.choice([0, 1]) for _ in range(num_samples)]\n",
    "\n",
    "# Plot del dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['blue' if label == 0 else 'red' for label in y]\n",
    "plt.scatter([x[0] for x in X], [x[1] for x in X], c=colors)\n",
    "plt.title('Dataset')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "# set legend according to color, shape is circular\n",
    "plt.legend(handles=[plt.Line2D([], [], color='blue', marker='o', linestyle='None'),\n",
    "                    plt.Line2D([], [], color='red', marker='o', linestyle='None')],\n",
    "           labels=['Classe 0', 'Classe 1'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vogliamo valutare le prestazioni di un modello di classificazione, in questo caso un modello di regressione logistica, su questo dataset utilizzando le metriche di valutazione per la classificazione binaria.\n",
    "\n",
    "Successivamente, abbiamo definito tre metriche di valutazione per la classificazione binaria: **accuracy** (accuratezza), **precision** (precisione) e **recall** (sensibilità). \n",
    "\n",
    "Queste metriche calcolano rispettivamente l'*accuratezza complessiva*, *la frazione di predizioni positive che sono corrette* e la *frazione di veri positivi individuati correttamente rispetto a tutti i positivi reali*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metriche di valutazione per la classificazione binaria\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = len(y_true)\n",
    "\n",
    "    for i in range(total):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = 0\n",
    "    predicted_positives = 0\n",
    "\n",
    "    for i in range(len(y_true)):\n",
    "        if y_pred[i] == 1:\n",
    "            predicted_positives += 1\n",
    "            if y_true[i] == 1:\n",
    "                true_positives += 1\n",
    "\n",
    "    return true_positives / predicted_positives if predicted_positives != 0 else 0\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = 0\n",
    "    actual_positives = 0\n",
    "\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            actual_positives += 1\n",
    "            if y_pred[i] == 1:\n",
    "                true_positives += 1\n",
    "\n",
    "    return true_positives / actual_positives if actual_positives != 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'esempio seguiamo la classica routine di un algoritmo di apprendimento automatico:\n",
    "\n",
    "1. Abbiamo diviso il dataset in un train set e un test set utilizzando una divisione casuale.\n",
    "2. Abbiamo addestrato il modello di classificazione utilizzando il train set.\n",
    "3. Abbiamo effettuato le previsioni delle etichette utilizzando il test set.\n",
    "4. Abbiamo calcolato le metriche di valutazione (accuratezza, precisione, sensibilità) utilizzando le etichette reali del test set e le previsioni effettuate dal modello.\n",
    "5. Abbiamo visualizzato i risultati delle metriche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione del dataset in train set e test set\n",
    "test_size = 0.2\n",
    "num_test_samples = int(num_samples * test_size)\n",
    "indices = list(range(num_samples))\n",
    "random.shuffle(indices)\n",
    "\n",
    "X_train = [X[i] for i in indices[num_test_samples:]]\n",
    "y_train = [y[i] for i in indices[num_test_samples:]]\n",
    "X_test = [X[i] for i in indices[:num_test_samples]]\n",
    "y_test = [y[i] for i in indices[:num_test_samples]]\n",
    "\n",
    "# Addestramento del modello di regressione logistica\n",
    "_, weights, bias = logistic_regression(X_train, y_train)\n",
    "\n",
    "# Previsione delle etichette\n",
    "def predict_logistic_regression(X_test, weights, bias):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        z = bias\n",
    "        for w, feature in zip(weights, x):\n",
    "            z += w * feature\n",
    "        y_pred.append(1 if sigmoid(z) >= 0.5 else 0)\n",
    "    return y_pred\n",
    "\n",
    "y_pred_logistic = predict_logistic_regression(X_test, weights, bias)\n",
    "\n",
    "# Calcolo delle metriche di valutazione\n",
    "acc = accuracy(y_test, y_pred_logistic)\n",
    "prec = precision(y_test, y_pred_logistic)\n",
    "rec = recall(y_test, y_pred_logistic)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(f'Accuracy: {acc:.2f}')\n",
    "print(f'Precision: {prec:.2f}')\n",
    "print(f'Recall: {rec:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olte i modelli lineari: classificazione con Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa implementazione rappresenta un **modello SVM lineare con l'uso di margini soft** (soft margin) e l'ottimizzazione dei pesi tramite l'algoritmo del gradiente. \n",
    "\n",
    "La funzione `train_svm` addestra il modello sui dati di input X e le relative etichette y. \n",
    "\n",
    "I parametri C, learning_rate e num_epochs controllano rispettivamente la penalizzazione degli errori, il tasso di apprendimento e il numero di epoche di addestramento.\n",
    "\n",
    "La funzione `predict_svm` utilizza il modello addestrato per effettuare le previsioni sulle nuove istanze di input X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Funzione di decisione per il modello SVM\n",
    "\n",
    "\n",
    "def svm_decision_function(X, w, b):\n",
    "    return np.dot(X, w) + b\n",
    "\n",
    "# Funzione di addestramento per il modello SVM\n",
    "\n",
    "\n",
    "def train_svm(X, y, C, learning_rate, num_epochs):\n",
    "    # convert X in numpy array\n",
    "    X = np.array(X)\n",
    "    num_samples, num_features = X.shape\n",
    "\n",
    "    # Inizializzazione dei pesi e del termine di offset\n",
    "    w = np.zeros(num_features)\n",
    "    b = 0\n",
    "\n",
    "    # Addestramento del modello\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(num_samples):\n",
    "            if y[i] * svm_decision_function(X[i], w, b) < 1:\n",
    "                # Aggiornamento dei pesi per campioni mal classificati\n",
    "                w = w + learning_rate * (y[i] * X[i] - C * w)\n",
    "                b = b + learning_rate * y[i]\n",
    "            else:\n",
    "                # Aggiornamento dei pesi per campioni correttamente classificati\n",
    "                w = w + learning_rate * (-C * w)\n",
    "\n",
    "    return w, b\n",
    "\n",
    "# Funzione di previsione per il modello SVM\n",
    "\n",
    "\n",
    "def predict_svm(X, w, b):\n",
    "    scores = svm_decision_function(X, w, b)\n",
    "    predictions = np.sign(scores)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esempio per SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo esempio, generiamo casualmente due gruppi di punti bidimensionali (`X1` e `X2`) corrispondenti a due classi diverse. \n",
    "\n",
    "Successivamente, combiniamo i due gruppi di punti per ottenere il dataset completo `X`, e assegniamo etichette positive (**classe 1**) ai punti di `X1` e etichette negative (**classe -1**) ai punti di `X2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "num_samples = 100\n",
    "\n",
    "X1 = [[random.gauss(2, 1), random.gauss(2, 1)] for _ in range(num_samples)]\n",
    "X2 = [[random.gauss(-2, 1), random.gauss(-2, 1)] for _ in range(num_samples)]\n",
    "X = X1 + X2\n",
    "\n",
    "y = [1] * num_samples + [-1] * num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successivamente, addestriamo il modello SVM utilizzando la funzione `train_svm`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento del modello SVM\n",
    "C = 0.01\n",
    "learning_rate = 0.1\n",
    "num_epochs = 100\n",
    "\n",
    "w, b = train_svm(X, y, C, learning_rate, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello addestrato viene quindi utilizzato per effettuare la previsione su un nuovo punto specificato come `new_point` con coordinate (0,0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsione su un nuovo punto\n",
    "new_point = np.array([0, 0])\n",
    "prediction = predict_svm(new_point, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, visualizziamo i dati di addestramento, la decision boundary calcolata dal modello SVM e il nuovo punto sul grafico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dei dati e della decision boundary\n",
    "# convert X to numpy array\n",
    "X = np.array(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# Creazione della griglia di punti per la decision boundary\n",
    "xx = np.linspace(xlim[0], xlim[1], 100)\n",
    "yy = np.linspace(ylim[0], ylim[1], 100)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = svm_decision_function(xy, w, b).reshape(XX.shape)\n",
    "\n",
    "# Plot della decision boundary\n",
    "ax.contour(XX, YY, Z, colors='k',\n",
    "           levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "ax.scatter(new_point[0], new_point[1], color='red',\n",
    "           marker='x', s=100, label='Nuovo punto')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.title('Support Vector Machine')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puoi sperimentare con questo esempio modificando i parametri come C, learning_rate, num_epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
